@article{liu.etal2018,
  title = {Time {{Series Forecasting}} of {{Air Quality Based On Regional Numerical Modeling}} in {{Hong Kong}}},
  author = {Liu, Tong and Lau, Alexis K. H. and Sandbrink, Kai and Fung, Jimmy C. H.},
  year = {2018},
  journal = {Journal of Geophysical Research: Atmospheres},
  volume = {123},
  number = {8},
  pages = {4175--4196},
  issn = {2169-8996},
  doi = {10.1002/2017JD028052},
  urldate = {2024-02-04},
  abstract = {Based on prevailing numerical forecasting models (Community Multiscale Air Quality [CMAQ] model , Comprehensive Air Quality Model with Extensions, and Nested Air Quality Prediction Modeling System) and observations from monitoring stations in Hong Kong, we employ a set of autoregressive integrated moving average (ARIMA) models with numerical forecasts (ARIMAX) to improve the forecast of air pollutants including PM2.5, NO2, and O3. The results show significant improvements in multiple evaluation metrics for daily (1{\textendash}3 days) and hourly (1{\textendash}72 hr) forecast. Forecasts on daily 1-hr and 8-hr maximum O3 are also improved. For instance, compared with CMAQ, applying CMAQ-ARIMA reduces average root-mean-square errors (RMSEs) at all stations for daily average PM2.5, NO2, and O3 in the next 3 days by 14.3{\textendash}21.0\%, 41.2{\textendash}46.3\%, and 47.8{\textendash}49.7\%, respectively. For hourly forecasts in the next 72 hr, reductions in RMSEs brought by ARIMAX using CMAQ are 18.2\% for PM2.5, 32.1\% for NO2, and 36.7\% for O3. Large improvements in RMSEs are achieved for nonrural PM2.5 and rural NO2 using ARIMAX with three numerical models. Dynamic hourly forecast shows that ARIMAX can be applied for forecast of 7- to 72-hr PM2.5, 4- to 72-hr NO2, and 4- to 6-hr O3. Besides applying ARIMAX for NO2, we recommend a mixed forecast strategy to ARIMAX for normal values of PM2.5 and O3 and employ numerical models for outputs above 75th percentile of historical observations. Our hybrid ARIMAX method can combine the advantage of ARIMA and numerical modeling to assist real-time air quality forecasting efficiently and consistently.},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {air quality,ARIMA,forecast,numerical model,stochastic model,time series},
  file = {C\:\\Users\\kjsan\\Zotero\\storage\\3VDDJ5NE\\Liu et al. - 2018 - Time Series Forecasting of Air Quality Based On Re.pdf;C\:\\Users\\kjsan\\Zotero\\storage\\L2MDEK5M\\2017JD028052.html},
}

@misc{mathis.etal2020,
  title = {{{DLC2Kinematics}}: A Post-Deeplabcut Module for Kinematic Analysis},
  shorttitle = {{{DLC2Kinematics}}},
  author = {Mathis, Mackenzie and Lauer, Jessy and Nath, Tanmay and Sandbrink, Kai and Beauzile, Michael and Hausmann, S{\'e}bastien and Schneider, Steffen and Mathis, Alexander},
  year = {2020},
  month = feb,
  doi = {10.5281/zenodo.8091911},
  urldate = {2024-02-04},
  abstract = {Kinematic analysis is crucial in biomedical, biomechanical, life sciences and medicine. Here, we present a python toolbox for analysis of markerless motion capture data~collected with DeepLabCut. This toolbox represents~the contributions of members of the Mathis Lab of Adaptive Motor Control from 2017-2023. Please see~https://github.com/AdaptiveMotorControlLab/DLC2Kinematics for up to date versions. We kindly ask that if you use this code you cite the software.},
  copyright = {All rights reserved},
  howpublished = {Zenodo},
  keywords = {deeplabcut},
  file = {C:\Users\kjsan\Zotero\storage\XLP9T78U\8091911.html}
}

@article{sandbrink.etal2023b,
  title = {Contrasting Action and Posture Coding with Hierarchical Deep Neural Network Models of Proprioception},
  author = {Sandbrink, Kai J and Mamidanna, Pranav and Michaelis, Claudio and Bethge, Matthias and Mathis, Mackenzie Weygandt and Mathis, Alexander},
  editor = {Ba, Demba and Behrens, Timothy E and Kriegeskorte, Nikolaus},
  year = {2023},
  month = may,
  journal = {eLife},
  volume = {12},
  pages = {e81499},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.81499},
  urldate = {2024-02-04},
  abstract = {Biological motor control is versatile, efficient, and depends on proprioceptive feedback. Muscles are flexible and undergo continuous changes, requiring distributed adaptive control mechanisms that continuously account for the body's state. The canonical role of proprioception is representing the body state. We hypothesize that the proprioceptive system could also be critical for high-level tasks such as action recognition. To test this theory, we pursued a task-driven modeling approach, which allowed us to isolate the study of proprioception. We generated a large synthetic dataset of human arm trajectories tracing characters of the Latin alphabet in 3D space, together with muscle activities obtained from a musculoskeletal model and model-based muscle spindle activity. Next, we compared two classes of tasks: trajectory decoding and action recognition, which allowed us to train hierarchical models to decode either the position and velocity of the end-effector of one's posture or the character (action) identity from the spindle firing patterns. We found that artificial neural networks could robustly solve both tasks, and the networks' units show tuning properties similar to neurons in the primate somatosensory cortex and the brainstem. Remarkably, we found uniformly distributed directional selective units only with the action-recognition-trained models and not the trajectory-decoding-trained models. This suggests that proprioceptive encoding is additionally associated with higher-level functions such as action recognition and therefore provides new, experimentally testable hypotheses of how proprioception aids in adaptive motor control.},
  copyright = {All rights reserved},
  keywords = {biomechanics,deep learning,proprioception,sensory systems,somatosensory,task-driven modeling},
  selected = {true},
}


@inproceedings{sandbrink.summerfield2023,
  title = {Learning the Value of Control with {{Deep RL}}},
  booktitle = {2023 {{Conference}} on {{Cognitive Computational Neuroscience}}},
  author = {Sandbrink, Kai and Summerfield, Christopher},
  year = {2023},
  publisher = {{Cognitive Computational Neuroscience}},
  address = {{Oxford, UK}},
  doi = {10.32470/CCN.2023.1640-0},
  urldate = {2023-11-09},
  copyright = {All rights reserved},
  file = {C:\Users\kjsan\Zotero\storage\AJ3Y3BKB\view_paper.html},
  selected={true},
}

@inproceedings{yiu.etal2023,
  title = {Children Prioritize Purely Exploratory Actions in Observe-vs.-Bet Tasks},
  booktitle = {Intrinsically-{{Motivated}} and {{Open-Ended Learning Workshop}} @{{NeurIPS2023}}},
  author = {Yiu, Eunice and Sandbrink, Kai and Gopnik, Alison},
  year = {2023},
  month = nov,
  urldate = {2024-02-04},
  abstract = {In reinforcement learning, agents often need to decide between selecting actions that are familiar and have previously yielded positive results (exploitation), and seeking new information that could allow them to uncover more effective actions (exploration). Understanding the specific kinds of heuristics and strategies that humans employ to solve this problem over the course of their development remains an open question in cognitive science and AI. In this study we develop an "observe or bet" task that separates "pure exploration'' from "pure exploitation.'' Participants have the option to either observe an instance of an outcome and receive no reward, or to bet on an action that is eventually rewarding, but offers no immediate feedback. We collected data from 56 five-to-seven-year-old children who completed the task at one of three different probability levels. We compared how children performed against both approximate solutions to the partially-observable Markov decision process and meta-RL models that were meta trained on the same decision making task across different probability levels. We found that the children observe significantly more than the two classes of algorithms. We then quantified how children's policies differ between the different probability levels by fitting probabilistic programming models and by calculating the likelihood of the children's actions under the task-driven model. The fitted parameters of the behavioral model as well as the direction of the deviation from neural network policies demonstrate that the primary way children change the frequency with which they bet on the door for which they have less evidence. This suggests both that children model the causal structure of the environment and that they produce a ``hedging behavior'' that would be impossible to detect in standard bandit tasks, and that reduces variance in overall rewards. The results shed light on how children reason about reward and information, providing a developmental benchmark that can help shape our understanding of both human behavior and RL neural network models.},
  copyright = {All rights reserved},
  langid = {english},
  file = {C:\Users\kjsan\Zotero\storage\AN9HNMTG\Yiu et al. - 2023 - Children prioritize purely exploratory actions in .pdf}
}
